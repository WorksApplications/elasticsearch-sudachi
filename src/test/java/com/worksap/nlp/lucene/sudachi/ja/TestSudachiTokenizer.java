/*
 *  Copyright (c) 2017 Works Applications Co., Ltd.
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */


package com.worksap.nlp.lucene.sudachi.ja;

import static org.hamcrest.CoreMatchers.is;

import java.io.File;
import java.io.IOException;
import java.io.InputStream;
import java.io.Reader;
import java.io.StringReader;

import org.apache.lucene.analysis.BaseTokenStreamTestCase;

import org.junit.Before;
import org.junit.Rule;
import org.junit.Test;
import org.junit.rules.TemporaryFolder;

// Test of character segmentation using incrementToken(tokenizer)
public class TestSudachiTokenizer extends BaseTokenStreamTestCase {
    private SudachiTokenizer tokenizer;
    private SudachiTokenizer tokenizerExtended;
    private SudachiTokenizer tokenizerNormal;
    private SudachiTokenizer tokenizerPunctuation;

    @Rule
    public TemporaryFolder tempFolderForDictionary = new TemporaryFolder();

    @Before
    public void setup() throws IOException {
        tempFolderForDictionary.create();
        File tempFileForDictionary = tempFolderForDictionary
                .newFolder("sudachiDictionary");
        ResourceUtil.copy(tempFileForDictionary);

        String settings;
        try(InputStream is = this.getClass()
                .getResourceAsStream("sudachi.json");){
            settings = ResourceUtil.getSudachiSetting(is);
        }

        tokenizer = new SudachiTokenizer(true, SudachiTokenizer.Mode.SEARCH,
                tempFileForDictionary.getPath(), settings);
        tokenizerExtended = new SudachiTokenizer(true,
                SudachiTokenizer.Mode.EXTENDED, tempFileForDictionary.getPath(), settings);
        tokenizerNormal = new SudachiTokenizer(true,
                SudachiTokenizer.Mode.NORMAL, tempFileForDictionary.getPath(), settings);
        tokenizerPunctuation = new SudachiTokenizer(false,
                SudachiTokenizer.Mode.SEARCH, tempFileForDictionary.getPath(), settings);
    }

    @Test
    public void incrementTokenWithShiftJis() throws IOException {
        String str = new String("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚".getBytes("Shift_JIS"), "Shift_JIS");
        tokenizer.setReader(new StringReader(str));
        assertTokenStreamContents(tokenizer,
                                  new String[] { "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 0, 2, 3, 4, 6 },
                                  new int[] { 3, 2, 3, 4, 6, 7 },
                                  new int[] { 1, 0, 1, 1, 1, 1 },
                                  new int[] { 2, 1, 1, 1, 1, 1 },
                                  8);
    }

    @Test
    public void incrementTokenByDefaultMode() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizer,
                                  new String[] { "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 0, 2, 3, 4, 6 },
                                  new int[] { 3, 2, 3, 4, 6, 7 },
                                  new int[] { 1, 0, 1, 1, 1, 1 },
                                  new int[] { 2, 1, 1, 1, 1, 1 },
                                  8);
    }

    @Test
    public void incrementTokenByExtendedMode() throws IOException {
        tokenizerExtended.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerExtended,
                                  new String[] { "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 0, 2, 3, 4, 6 },
                                  new int[] { 3, 2, 3, 4, 6, 7 },
                                  new int[] { 1, 0, 1, 1, 1, 1 },
                                  new int[] { 2, 1, 1, 1, 1, 1 },
                                  8);
    }

    @Test
    public void incrementTokenByNormalMode() throws IOException {
        tokenizerNormal.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerNormal,
                                  new String[] { "æ±äº¬éƒ½", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 3, 4, 6 },
                                  new int[] { 3, 4, 6, 7 },
                                  new int[] { 1, 1, 1, 1 },
                                  new int[] { 1, 1, 1, 1 },
                                  8);
    }

    @Test
    public void incrementTokenByPunctuationMode() throws IOException {
        tokenizerPunctuation.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerPunctuation,
                                  new String[] { "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ", "ã€‚" },
                                  new int[] { 0, 0, 2, 3, 4, 6, 7 },
                                  new int[] { 3, 2, 3, 4, 6, 7, 8 },
                                  new int[] { 1, 0, 1, 1, 1, 1, 1 },
                                  new int[] { 2, 1, 1, 1, 1, 1, 1 },
                                  8);
    }

    @Test
    public void incrementTokenWithPunctuationsByDefaultMode() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizer,
                                  new String[] { "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ", "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 0, 2, 3, 4, 6, 8, 8, 10, 11, 12, 14 },
                                  new int[] { 3, 2, 3, 4, 6, 7, 11, 10, 11, 12, 14, 15 },
                                  new int[] { 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1 },
                                  new int[] { 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1 },
                                  16);
    }

    @Test
    public void incrementTokenWithPunctuationsByExtendedMode() throws IOException {
        tokenizerExtended.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerExtended,
                                  new String[] { "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ", "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 0, 2, 3, 4, 6, 8, 8, 10, 11, 12, 14 },
                                  new int[] { 3, 2, 3, 4, 6, 7, 11, 10, 11, 12, 14, 15 },
                                  new int[] { 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1 },
                                  new int[] { 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1 },
                                  16);
    }

    @Test
    public void incrementTokenWithPunctuationsByNormalMode() throws IOException {
        tokenizerNormal.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerNormal,
                                  new String[] { "æ±äº¬éƒ½", "ã«", "è¡Œã£", "ãŸ", "æ±äº¬éƒ½", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 3, 4, 6, 8, 11, 12, 14 },
                                  new int[] { 3, 4, 6, 7, 11, 12, 14, 15 },
                                  new int[] { 1, 1, 1, 1, 1, 1, 1, 1 },
                                  new int[] { 1, 1, 1, 1, 1, 1, 1, 1 },
                                  16);
    }

    @Test
    public void incrementTokenWithPunctuationsByPunctuationMode() throws IOException {
        tokenizerPunctuation.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerPunctuation,
                                  new String[] { "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ", "ã€‚", "æ±äº¬éƒ½", "æ±äº¬", "éƒ½", "ã«", "è¡Œã£", "ãŸ", "ã€‚" },
                                  new int[] { 0, 0, 2, 3, 4, 6, 7, 8, 8, 10, 11, 12, 14, 15 },
                                  new int[] { 3, 2, 3, 4, 6, 7, 8, 11, 10, 11, 12, 14, 15, 16 },
                                  new int[] { 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1 },
                                  new int[] { 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1 },
                                  16);
    }

    @Test
    public void incrementTokenWithOOVByDefaultMode() throws IOException {
        tokenizer.setReader(new StringReader("ã‚¢ãƒã‚¾ãƒ³ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizer,
                                  new String[] { "ã‚¢ãƒã‚¾ãƒ³", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 4, 5, 7 },
                                  new int[] { 4, 5, 7, 8 },
                                  new int[] { 1, 1, 1, 1 },
                                  new int[] { 1, 1, 1, 1 },
                                  9);
    }

    @Test
    public void incrementTokenWithOOVByExtendedMode() throws IOException {
        tokenizerExtended.setReader(new StringReader("ã‚¢ãƒã‚¾ãƒ³ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerExtended,
                                  new String[] { "ã‚¢ãƒã‚¾ãƒ³", "ã‚¢", "ãƒ", "ã‚¾", "ãƒ³", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 0, 1, 2, 3, 4, 5, 7 },
                                  new int[] { 4, 1, 2, 3, 4, 5, 7, 8 },
                                  new int[] { 1, 0, 1, 1, 1, 1, 1, 1 },
                                  new int[] { 4, 1, 1, 1, 1, 1, 1, 1 },
                                  9);
    }

    @Test
    public void incrementTokenWithOOVByNormalMode() throws IOException {
        tokenizerNormal.setReader(new StringReader("ã‚¢ãƒã‚¾ãƒ³ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerNormal,
                                  new String[] { "ã‚¢ãƒã‚¾ãƒ³", "ã«", "è¡Œã£", "ãŸ" },
                                  new int[] { 0, 4, 5, 7 },
                                  new int[] { 4, 5, 7, 8 },
                                  new int[] { 1, 1, 1, 1 },
                                  new int[] { 1, 1, 1, 1 },
                                  9);
    }

    @Test
    public void incrementTokenWithOOVByPunctuationMode() throws IOException {
        tokenizerPunctuation.setReader(new StringReader("ã‚¢ãƒã‚¾ãƒ³ã«è¡Œã£ãŸã€‚"));
        assertTokenStreamContents(tokenizerPunctuation,
                                  new String[] { "ã‚¢ãƒã‚¾ãƒ³", "ã«", "è¡Œã£", "ãŸ", "ã€‚" },
                                  new int[] { 0, 4, 5, 7, 8 },
                                  new int[] { 4, 5, 7, 8, 9 },
                                  new int[] { 1, 1, 1, 1, 1 },
                                  new int[] { 1, 1, 1, 1, 1 },
                                  9);
    }

    @Test
    public void testReadSentences() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        tokenizer.reset();
        assertThat(tokenizer.readSentences(), is("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));

        tokenizerExtended.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        tokenizerExtended.reset();
        assertThat(tokenizerExtended.readSentences(), is("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
    }

    @Test
    public void testReadSentencesWithTwoSentences() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
        tokenizer.reset();
        assertThat(tokenizer.readSentences(), is("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚"));
    }

    @Test
    public void testReadSentencesWithoutLastPunctuation() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸ"));
        tokenizer.reset();
        String[] answerList = { "æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚", "æ±äº¬éƒ½ã«è¡Œã£ãŸ" };
        for (int i = 0; i < answerList.length; i++) {
            assertThat(tokenizer.readSentences(), is(answerList[i]));
        }
    }

    @Test
    public void testReadSentencesWithTwoPunctuations() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚ã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸ"));
        tokenizer.reset();
        String[] answerList = { "æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚ã€‚", "æ±äº¬éƒ½ã«è¡Œã£ãŸ" };
        for (int i = 0; i < answerList.length; i++) {
            assertThat(tokenizer.readSentences(), is(answerList[i]));
        }
    }

    @Test
    public void testReadSentencesWithIdeographicComma() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€æ±äº¬éƒ½ã«è¡Œã£ãŸ"));
        tokenizer.reset();
        String[] answerList = { "æ±äº¬éƒ½ã«è¡Œã£ãŸã€", "æ±äº¬éƒ½ã«è¡Œã£ãŸ" };
        for (int i = 0; i < answerList.length; i++) {
            assertThat(tokenizer.readSentences(), is(answerList[i]));
        }
    }

    @Test
    public void testReadSentencesWithPeriod() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚ã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸ."));
        tokenizer.reset();
        assertThat(tokenizer.readSentences(), is("æ±äº¬éƒ½ã«è¡Œã£ãŸã€‚ã€‚æ±äº¬éƒ½ã«è¡Œã£ãŸ."));
    }

    @Test
    public void testReadSentencesWithComma() throws IOException {
        tokenizer.setReader(new StringReader("æ±äº¬éƒ½ã«è¡Œã£ãŸ,æ±äº¬éƒ½ã«è¡Œã£ãŸ"));
        tokenizer.reset();
        String[] answerList = { "æ±äº¬éƒ½ã«è¡Œã£ãŸ,", "æ±äº¬éƒ½ã«è¡Œã£ãŸ" };
        for (int i = 0; i < answerList.length; i++) {
            assertThat(tokenizer.readSentences(), is(answerList[i]));
        }
    }

    @Test
    public void testReadSentencesWithLongSentence() throws IOException {
        tokenizer.setReader(new StringReader("å²©æ³¢æ–‡åº«ã¯å¹³ç¦ç™¾ç©‚ç”»ä¼¯ã®è£…å¹€ã‚’ã‚‚ã£ã¦æ˜­å’ŒäºŒå¹´åˆŠè¡Œã•ã‚ŒãŸã€‚"
                + "ã“ã‚Œã‚’ç™ºè¡¨ã—ãŸæ™‚ã®å½±éŸ¿ã®çµ¶å¤§ãªã‚Šã—ã“ã¨ã¯å®Ÿã«é©šã„ãŸã€‚" + "è®ƒç¾ã€æ¿€åŠ±ã€å¸Œæœ›ç­‰ã®æ›¸ä¿¡ãŒæ•°åƒé€šã«é”ã—ãŸã€‚"
                + "ã€Œç§ã®æ•™é¤Šã®ä¸€åˆ‡ã‚’å²©æ³¢æ–‡åº«ã«æ‰˜ã™ã‚‹ã€ãªã©ã¨ã„ã†æ„Ÿæ¿€ã®æ–‡å­—ã‚‚ã‚ã£ãŸã€‚"
                + "ç§ã¯ã‚ˆã„ä»•äº‹ã ã€é«˜è²´ãªæ°¸é ã®äº‹æ¥­ã ã€é”æˆã™ã¹ãä¼ã¦ã ã€"
                + "å¾Œã«ã¯å¿…ãšæˆå°±ã™ã‚‹ä»•äº‹ã ã¨è€ƒãˆãŸãŒã€ã‹ãã¾ã§é€Ÿã‹ã«ã€ã‹ãã¾ã§ç››ã‚“ã«æ­“è¿ã•ã‚Œã‚‹ã¨ã¯æ€ã‚ãªã‹ã£ãŸã€‚"
                + "Du kannst, denn du sollst. ã¯ç§ã®çµ¶æ„›ã®å¥ã§ã‚ã‚‹ãŒã€èª å¿ƒèª æ„ã€"
                + "èª­æ›¸å­ã®ãŸã‚ã«è¨ˆã‚‹ä»•äº‹ã¯å¿…ãšé…¬ã„ã‚‰ã‚Œã‚‹ã‚‚ã®ã§ã‚ã‚‹ã¨ã®ç¢ºä¿¡ã‚’å¾—ãŸã€‚"
                + "ç§ã¯æœ¬å±‹ã«ãªã£ãŸç”²æ–ã®ã‚ã£ãŸã“ã¨ã‚’åˆã‚ã¦çŸ¥ã‚Šã€è²¬ä»»ã®ã¾ã™ã¾ã™é‡ãã‚’ç—›æ„Ÿã—ãŸã€‚ã€€"
                + "å²©æ³¢æ–‡åº«ã¯å¤ä»Šæ±è¥¿ã®å¤å…¸ã®æ™®åŠã‚’ä½¿å‘½ã¨ã™ã‚‹ã€‚å¤å…¸ã®å°Šé‡ã™ã¹ãã¯è¨€ã†ã¾ã§ã‚‚ãªã„ã€‚"
                + "ãã®æ™®åŠã®ç¨‹åº¦ã¯ç›´ã¡ã«æ–‡åŒ–ã®æ°´æº–ã‚’ç¤ºã™ã‚‚ã®ã§ã‚ã‚‹ã€‚ã—ãŸãŒã£ã¦æ–‡åº«å‡ºç‰ˆã«ã¤ã„ã¦ã¯æ•¬è™”ãªã‚‹æ…‹åº¦ã‚’æŒã—ã€"
                + "å¤å…¸ã«å¯¾ã™ã‚‹å°Šæ•¬ã¨æ„›ã¨ã‚’å¤±ã£ã¦ã¯ãªã‚‰ãªã„ã€‚ç§ã¯åŠã°ãšãªãŒã‚‰ã‚‚ã“ã®ç†æƒ³ã‚’å®Ÿç¾ã—ã‚ˆã†ã¨å¿ƒãŒã‘ã€"
                + "ä¸€èˆ¬å˜è¡Œæœ¬ã«å¯¾ã™ã‚‹ã‚ˆã‚Šã‚‚ã€ã•ã‚‰ã«å³ç²›ãªã‚‹æ…‹åº¦ã‚’ã‚‚ã£ã¦æ–‡åº«ã®å‡ºç‰ˆã«è‡¨ã‚“ã ã€‚"
                + "æ–‡åº«ã®ç·¨å…¥ã™ã¹ãå…¸ç±ã®å³é¸ã¯ã‚‚ã¡ã‚ã‚“ã€ç·¨é›†ã€æ ¡è¨‚ã€ç¿»è¨³ç­‰ã€"
                + "ãã®é“ã®æ¨©å¨è€…ã‚’ç…©ã‚ã—ã¦æœ€å–„ã‚’ã¤ãã™ã“ã¨ã«äººçŸ¥ã‚Œã¬è‹¦å¿ƒã‚’ã—ãŸã®ã§ã‚ã‚‹ã€‚"
                + "å¾“æ¥è¡Œãªã‚ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’ãã®ã¾ã¾ç·¨å…¥ã™ã‚Œã°ä¾¿å®œãªã‚‹æ™‚ã‚‚ã€"
                + "ã‚ˆã‚Šã‚ˆã„åŸç¨¿ã‚’å¾—ã‚‹ãŸã‚ã«æ–°ãŸã«æœ€é©ä»»è€…ã«æ‡‡è«‹ã—ã¦æ•°å¹´ã‚’è²»ã‚„ã—ã¦ã‚ˆã†ã‚„ãåˆŠè¡Œã™ã‚‹ã«è‡³ã£ãŸä¾‹ã‚‚å°‘ãªããªã„ã€‚"
                + "ã—ã‹ã‚‹ã«ã“ã®æ…‹åº¦ã¯ä»Šã‚‚ãªãŠä¸€èˆ¬ã«ç†è§£ã•ã‚Œãšã€"
                + "å¾€ã€…ã«ã—ã¦è‘—è€…ã‹ã‚‰è¬™éœã®ã¤ã‚‚ã‚Šã§æ–‡åº«ã«ã§ã‚‚å…¥ã‚Œã¦ã‚‚ã‚‰ã„ãŸã„ãªã©å‡ºç‰ˆã‚’ç”³ã—è¾¼ã¾ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã€‚"
                + "ç§ã¯å˜è¡Œæœ¬ã«ã¯å¼•ãå—ã‘ã‚‰ã‚Œã¦ã‚‚æ–‡åº«ã«ã¯å¼•ãå—ã‘ã¬ã¨ã„ã£ã¦æ‹’çµ¶ã™ã‚‹ã»ã©ã€æ–‡åº«ã‚’å°Šé‡æ„›è­·ã™ã‚‹ã®ã§ã‚ã‚‹ã€‚ã€€"
                + "å…¸ç±ã®ç¯„å›²ã‚’ã„ãšã‚Œã«é™å®šã™ã¹ãã‹ã€å¾“æ¥æ—¢åˆŠã®å²©æ³¢æ–‡åº«ã‚’è¦‹ã‚‹ã«å¿…ãšã—ã‚‚æ¨™æº–ãŒä¸€å®šã—ãªã‹ã£ãŸã†ã‚‰ã¿ãŒã‚ã‚‹ãŒã€"
                + "ä»Šå¾Œã®æ–¹é‡ã¨ã—ã¦ã¯å¤å…¸çš„ä¾¡å€¤ã®æ°´æº–ã‚’ã¾ã™ã¾ã™é«˜ã‚ã‚‹ã¨ã¨ã‚‚ã«ã€å³é¸æ–¹é‡ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã«ã—ãŸã€‚"
                + "çµŒæ¸ˆçš„ä¾¡å€¤é«˜ãã¨ã‚‚æœ¬è³ªçš„ä¾¡å€¤ä¹ã—ã„ã‚‚ã®ã¯ã“ã‚Œã‚’ç·¨å…¥ã—ãªã„ã“ã¨ã«ç‰¹ã«æ„ã‚’ç”¨ã„ã‚‹ã¨ã¨ã‚‚ã«ã€"
                + "çµŒæ¸ˆçš„ä¾¡å€¤ä½ãã¨ã‚‚å¤å…¸çš„ä¾¡å€¤ã®è±Šã‹ãªã‚‹ã‚‚ã®ã¯ã¤ã¨ã‚ã¦ç·¨å…¥ã—ã€ã“ã®ç‚¹ã«ãŠã„ã¦å²©æ³¢æ–‡åº«æœ¬æ¥ã®ç‰¹è‰²ã‚’ç™ºæ®ã—ã‚ˆã†ã¨æ€ã£ã¦ã„ã‚‹ã€‚"
                + "å¾€å¹´å¤–éŠã®éš›ã€ãƒ¬ã‚¯ãƒ©ãƒ ä¼šç¤¾ã‚’è¦‹å­¦ã—ã¦ãã®äº‹æ¥­çš„è¦æ¨¡ã®å¤§ãªã‚‹ã«ã¯é©šã„ãŸãŒã€"
                + "ç·¨é›†æ…‹åº¦ã«ãŠã„ã¦ã¯å²©æ³¢æ–‡åº«ãŒã€ãã®å…ˆè¹¤ãŸã‚‹ãƒ¬ã‚¯ãƒ©ãƒ æ–‡åº«ã‚’æ¥ãšã‹ã—ã‚€ã‚‹ã‚‚ã®ã§ãªã„ã¨ã€ã²ãã‹ã«æ…°ã‚€ã‚‹ã¨ã“ã‚ãŒã‚ã£ãŸã€‚"));
        tokenizer.reset();
        String[] answerList = {
                "å²©æ³¢æ–‡åº«ã¯å¹³ç¦ç™¾ç©‚ç”»ä¼¯ã®è£…å¹€ã‚’ã‚‚ã£ã¦æ˜­å’ŒäºŒå¹´åˆŠè¡Œã•ã‚ŒãŸã€‚"
                        + "ã“ã‚Œã‚’ç™ºè¡¨ã—ãŸæ™‚ã®å½±éŸ¿ã®çµ¶å¤§ãªã‚Šã—ã“ã¨ã¯å®Ÿã«é©šã„ãŸã€‚"
                        + "è®ƒç¾ã€æ¿€åŠ±ã€å¸Œæœ›ç­‰ã®æ›¸ä¿¡ãŒæ•°åƒé€šã«é”ã—ãŸã€‚"
                        + "ã€Œç§ã®æ•™é¤Šã®ä¸€åˆ‡ã‚’å²©æ³¢æ–‡åº«ã«æ‰˜ã™ã‚‹ã€ãªã©ã¨ã„ã†æ„Ÿæ¿€ã®æ–‡å­—ã‚‚ã‚ã£ãŸã€‚"
                        + "ç§ã¯ã‚ˆã„ä»•äº‹ã ã€é«˜è²´ãªæ°¸é ã®äº‹æ¥­ã ã€é”æˆã™ã¹ãä¼ã¦ã ã€å¾Œã«ã¯å¿…ãšæˆå°±ã™ã‚‹ä»•äº‹ã ã¨è€ƒãˆãŸãŒã€"
                        + "ã‹ãã¾ã§é€Ÿã‹ã«ã€ã‹ãã¾ã§ç››ã‚“ã«æ­“è¿ã•ã‚Œã‚‹ã¨ã¯æ€ã‚ãªã‹ã£ãŸã€‚Du kannst, denn du sollst. ã¯ç§ã®çµ¶æ„›ã®å¥ã§ã‚ã‚‹ãŒã€"
                        + "èª å¿ƒèª æ„ã€èª­æ›¸å­ã®ãŸã‚ã«è¨ˆã‚‹ä»•äº‹ã¯å¿…ãšé…¬ã„ã‚‰ã‚Œã‚‹ã‚‚ã®ã§ã‚ã‚‹ã¨ã®ç¢ºä¿¡ã‚’å¾—ãŸã€‚"
                        + "ç§ã¯æœ¬å±‹ã«ãªã£ãŸç”²æ–ã®ã‚ã£ãŸã“ã¨ã‚’åˆã‚ã¦çŸ¥ã‚Šã€è²¬ä»»ã®ã¾ã™ã¾ã™é‡ãã‚’ç—›æ„Ÿã—ãŸã€‚ã€€"
                        + "å²©æ³¢æ–‡åº«ã¯å¤ä»Šæ±è¥¿ã®å¤å…¸ã®æ™®åŠã‚’ä½¿å‘½ã¨ã™ã‚‹ã€‚å¤å…¸ã®å°Šé‡ã™ã¹ãã¯è¨€ã†ã¾ã§ã‚‚ãªã„ã€‚"
                        + "ãã®æ™®åŠã®ç¨‹åº¦ã¯ç›´ã¡ã«æ–‡åŒ–ã®æ°´æº–ã‚’ç¤ºã™ã‚‚ã®ã§ã‚ã‚‹ã€‚ã—ãŸãŒã£ã¦æ–‡åº«å‡ºç‰ˆã«ã¤ã„ã¦ã¯æ•¬è™”ãªã‚‹æ…‹åº¦ã‚’æŒã—ã€"
                        + "å¤å…¸ã«å¯¾ã™ã‚‹å°Šæ•¬ã¨æ„›ã¨ã‚’å¤±ã£ã¦ã¯ãªã‚‰ãªã„ã€‚ç§ã¯åŠã°ãšãªãŒã‚‰ã‚‚ã“ã®ç†æƒ³ã‚’å®Ÿç¾ã—ã‚ˆã†ã¨å¿ƒãŒã‘ã€ä¸€èˆ¬å˜è¡Œæœ¬ã«å¯¾ã™ã‚‹ã‚ˆã‚Šã‚‚ã€"
                        + "ã•ã‚‰ã«å³ç²›ãªã‚‹æ…‹åº¦ã‚’ã‚‚ã£ã¦æ–‡åº«ã®å‡ºç‰ˆã«è‡¨ã‚“ã ã€‚æ–‡åº«ã®ç·¨å…¥ã™ã¹ãå…¸ç±ã®å³é¸ã¯ã‚‚ã¡ã‚ã‚“ã€ç·¨é›†ã€æ ¡è¨‚ã€ç¿»è¨³ç­‰ã€",
                "ãã®é“ã®æ¨©å¨è€…ã‚’ç…©ã‚ã—ã¦æœ€å–„ã‚’ã¤ãã™ã“ã¨ã«äººçŸ¥ã‚Œã¬è‹¦å¿ƒã‚’ã—ãŸã®ã§ã‚ã‚‹ã€‚å¾“æ¥è¡Œãªã‚ã‚Œã¦ã„ã‚‹ã‚‚ã®ã‚’ãã®ã¾ã¾ç·¨å…¥ã™ã‚Œã°ä¾¿å®œãªã‚‹æ™‚ã‚‚ã€"
                        + "ã‚ˆã‚Šã‚ˆã„åŸç¨¿ã‚’å¾—ã‚‹ãŸã‚ã«æ–°ãŸã«æœ€é©ä»»è€…ã«æ‡‡è«‹ã—ã¦æ•°å¹´ã‚’è²»ã‚„ã—ã¦ã‚ˆã†ã‚„ãåˆŠè¡Œã™ã‚‹ã«è‡³ã£ãŸä¾‹ã‚‚å°‘ãªããªã„ã€‚"
                        + "ã—ã‹ã‚‹ã«ã“ã®æ…‹åº¦ã¯ä»Šã‚‚ãªãŠä¸€èˆ¬ã«ç†è§£ã•ã‚Œãšã€"
                        + "å¾€ã€…ã«ã—ã¦è‘—è€…ã‹ã‚‰è¬™éœã®ã¤ã‚‚ã‚Šã§æ–‡åº«ã«ã§ã‚‚å…¥ã‚Œã¦ã‚‚ã‚‰ã„ãŸã„ãªã©å‡ºç‰ˆã‚’ç”³ã—è¾¼ã¾ã‚Œã‚‹å ´åˆãŒã‚ã‚‹ã€‚"
                        + "ç§ã¯å˜è¡Œæœ¬ã«ã¯å¼•ãå—ã‘ã‚‰ã‚Œã¦ã‚‚æ–‡åº«ã«ã¯å¼•ãå—ã‘ã¬ã¨ã„ã£ã¦æ‹’çµ¶ã™ã‚‹ã»ã©ã€æ–‡åº«ã‚’å°Šé‡æ„›è­·ã™ã‚‹ã®ã§ã‚ã‚‹ã€‚ã€€"
                        + "å…¸ç±ã®ç¯„å›²ã‚’ã„ãšã‚Œã«é™å®šã™ã¹ãã‹ã€å¾“æ¥æ—¢åˆŠã®å²©æ³¢æ–‡åº«ã‚’è¦‹ã‚‹ã«å¿…ãšã—ã‚‚æ¨™æº–ãŒä¸€å®šã—ãªã‹ã£ãŸã†ã‚‰ã¿ãŒã‚ã‚‹ãŒã€"
                        + "ä»Šå¾Œã®æ–¹é‡ã¨ã—ã¦ã¯å¤å…¸çš„ä¾¡å€¤ã®æ°´æº–ã‚’ã¾ã™ã¾ã™é«˜ã‚ã‚‹ã¨ã¨ã‚‚ã«ã€å³é¸æ–¹é‡ã‚’å¼·åŒ–ã™ã‚‹ã“ã¨ã«ã—ãŸã€‚"
                        + "çµŒæ¸ˆçš„ä¾¡å€¤é«˜ãã¨ã‚‚æœ¬è³ªçš„ä¾¡å€¤ä¹ã—ã„ã‚‚ã®ã¯ã“ã‚Œã‚’ç·¨å…¥ã—ãªã„ã“ã¨ã«ç‰¹ã«æ„ã‚’ç”¨ã„ã‚‹ã¨ã¨ã‚‚ã«ã€"
                        + "çµŒæ¸ˆçš„ä¾¡å€¤ä½ãã¨ã‚‚å¤å…¸çš„ä¾¡å€¤ã®è±Šã‹ãªã‚‹ã‚‚ã®ã¯ã¤ã¨ã‚ã¦ç·¨å…¥ã—ã€"
                        + "ã“ã®ç‚¹ã«ãŠã„ã¦å²©æ³¢æ–‡åº«æœ¬æ¥ã®ç‰¹è‰²ã‚’ç™ºæ®ã—ã‚ˆã†ã¨æ€ã£ã¦ã„ã‚‹ã€‚"
                        + "å¾€å¹´å¤–éŠã®éš›ã€ãƒ¬ã‚¯ãƒ©ãƒ ä¼šç¤¾ã‚’è¦‹å­¦ã—ã¦ãã®äº‹æ¥­çš„è¦æ¨¡ã®å¤§ãªã‚‹ã«ã¯é©šã„ãŸãŒã€ç·¨é›†æ…‹åº¦ã«ãŠã„ã¦ã¯å²©æ³¢æ–‡åº«ãŒã€"
                        + "ãã®å…ˆè¹¤ãŸã‚‹ãƒ¬ã‚¯ãƒ©ãƒ æ–‡åº«ã‚’æ¥ãšã‹ã—ã‚€ã‚‹ã‚‚ã®ã§ãªã„ã¨ã€", "ã²ãã‹ã«æ…°ã‚€ã‚‹ã¨ã“ã‚ãŒã‚ã£ãŸã€‚" };
        for (int i = 0; i < answerList.length; i++) {
            assertThat(tokenizer.readSentences(), is(answerList[i]));
        }
    }

    @Test
    public void testReadSentencesWithSurrogatePair() throws IOException {
        int BUFFER_SIZE = 512;
        String beforeSurrogatePair = "";
        for (int i = 0; i < BUFFER_SIZE - 1; i++) {
            beforeSurrogatePair += "a";
        }
        String afterSurrogatePair = "bbb";
        String inputString = beforeSurrogatePair + "ğŸ˜œ" + afterSurrogatePair;
        tokenizer.setReader(new StringReader(inputString));
        tokenizer.reset();
        String[] answerList = { beforeSurrogatePair, "ğŸ˜œ" + afterSurrogatePair };
        for (int i = 0; i < answerList.length; i++) {
            assertThat(tokenizer.readSentences(), is(answerList[i]));
        }
    }

    private static class ChunkedStringReader extends Reader {
        private char[] in;
        private int chunkSize;
        private int pos;
        public ChunkedStringReader(String in, int chunkSize) {
            this.in = in.toCharArray();
            this.chunkSize = chunkSize;
            this.pos = 0;
        }

        @Override
        public void close() throws IOException {
            this.pos = this.in.length;
        }

        @Override
        public int read(char[] cbuf, int off, int len) throws IOException {
            int length = len < this.chunkSize ? len : this.chunkSize;
            if (length > this.in.length - this.pos) {
                length = this.in.length - this.pos;
            }
            if (length == 0) {
                return -1;
            }
            System.arraycopy(this.in, this.pos, cbuf, off, length);
            this.pos += length;
            return length;
        }
    }

    @Test
    public void testReadSentencesFromChunkedCharFilter() throws IOException {
        String inputString = "Elasticsearch";
        Reader charFilter = new ChunkedStringReader(inputString, 5);
        tokenizer.setReader(charFilter);
        tokenizer.reset();
        String[] answerList = { "Elasticsearch" };
        for (int i = 0; i < answerList.length; i++) {
            assertThat(tokenizer.readSentences(), is(answerList[i]));
        }
    }

}
